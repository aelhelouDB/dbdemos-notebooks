{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3534271-e1d8-4d17-837b-bdd44a7a4bfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Generate Eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023cd9f1-a1ec-4a88-9d55-a185bcef898f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105ca9cc-741a-4375-aada-1123ef202e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'use catalog {catalog}')\n",
    "spark.sql(f'use schema {dbName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d9eca9f-2643-4823-9c90-2429a601a293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id, pandas_udf, concat_ws, lit, col, from_json, struct, expr\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load 20 customers\n",
    "df = spark.table(\"customers\").limit(20).withColumn(\"row_id\", monotonically_increasing_id())\n",
    "\n",
    "# Step 2: Generate question using 20 templates\n",
    "@pandas_udf(StringType())\n",
    "def generate_question(first: pd.Series, last: pd.Series, row_id: pd.Series) -> pd.Series:\n",
    "    templates = [\n",
    "        \"What is the phone number of {email}?\",\n",
    "        \"List all orders placed by {email}.\",\n",
    "        \"What is the current subscription status for {email}?\",\n",
    "        \"Show billing details for {email}.\",\n",
    "        \"Does {email} have any unpaid invoices?\",\n",
    "        \"Which products did {email} purchase?\",\n",
    "        \"What is the loyalty tier of {email}?\",\n",
    "        \"When did {email} register as a customer?\",\n",
    "        \"Summarize all subscriptions held by {email}.\",\n",
    "        \"What city does {email} live in?\",\n",
    "        \"What is the current account status of {email}?\",\n",
    "        \"How many years has {email} been a customer?\",\n",
    "        \"What is the churn risk score for {email}?\",\n",
    "        \"What is the customer value score for {email}?\",\n",
    "        \"Is autopay enabled for {email}'s account?\",\n",
    "        \"How many late payments has {email} had?\",\n",
    "        \"What is the zip code of {email}?\",\n",
    "        \"What type of customer is {email} (e.g., Individual, Business)?\",\n",
    "        \"What is the full address of {email}?\"\n",
    "    ]\n",
    "    return pd.Series([\n",
    "        templates[int(i) % len(templates)].format(first_name=f, last_name=l)\n",
    "        for i, f, l in zip(row_id, first, last)\n",
    "    ])\n",
    "\n",
    "df = df.withColumn(\"question\", generate_question(\"first_name\", \"last_name\", \"row_id\"))\n",
    "\n",
    "# Step 3: Convert to Pandas then back to Spark to finalize UDF materialization\n",
    "df_pd = df.toPandas()\n",
    "df_clean = spark.createDataFrame(df_pd)\n",
    "\n",
    "# Step 4: Build prompt for AI_QUERY\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"prompt\",\n",
    "    concat_ws(\n",
    "        \" \",\n",
    "        lit(\"You are evaluating an AI system.\"),\n",
    "        lit(\"Based on the following customer record:\"),\n",
    "        concat_ws(\", \",\n",
    "            df_clean.first_name, df_clean.last_name, df_clean.email, df_clean.phone,\n",
    "            df_clean.address, df_clean.city, df_clean.state, df_clean.zip_code,\n",
    "            df_clean.customer_segment, df_clean.registration_date.cast(\"string\"),\n",
    "            df_clean.customer_status, df_clean.loyalty_tier,\n",
    "            df_clean.tenure_years.cast(\"string\"), df_clean.churn_risk_score.cast(\"string\"),\n",
    "            df_clean.customer_value_score.cast(\"string\")\n",
    "        ),\n",
    "        lit(\"Generate a JSON array of factual statements (expected_facts) that should be included in the correct answer to the following question. Each item must be a complete, natural language sentence. Return only a valid JSON array of strings, nothing else.\"),\n",
    "        lit(\"Question:\"), df_clean.question\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 5: Register and call AI_QUERY\n",
    "df_clean.createOrReplaceTempView(\"customer_test_questions\")\n",
    "\n",
    "final_df_raw = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  question,\n",
    "  AI_QUERY(\"databricks-claude-3-7-sonnet\", prompt) AS expected_facts_json\n",
    "FROM customer_test_questions\n",
    "\"\"\")\n",
    "\n",
    "# Step 6: Parse JSON string into Array<String>\n",
    "final_df = final_df_raw.withColumn(\n",
    "    \"expected_facts\",\n",
    "    from_json(col(\"expected_facts_json\"), ArrayType(StringType()))\n",
    ")\n",
    "\n",
    "# Step 7: Build structured evaluation format\n",
    "eval_df = final_df.withColumn(\"inputs\", struct(\"question\")) \\\n",
    "                  .withColumn(\"predictions\", lit(\"\")) \\\n",
    "                  .withColumn(\"expectations\", struct(\"expected_facts\")) \\\n",
    "                  .select(\"inputs\", \"predictions\", \"expectations\")\n",
    "\n",
    "# Step 8: Save\n",
    "eval_df.write.format('json').mode(\"overwrite\").save(f\"/Volumes/{catalog}/{dbName}/{volume_name}/eval_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86576658-ec1d-4e82-95c0-7f924e0a15d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, lit, from_json, explode, struct\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "\n",
    "# Step 1: Load 10 guides\n",
    "guides_df = spark.table(\"knowledge_base\").limit(10)\n",
    "\n",
    "# Step 2: Create prompt for question generation\n",
    "guides_with_prompts = guides_df.withColumn(\n",
    "    \"question_prompt\",\n",
    "    concat_ws(\n",
    "        \" \",\n",
    "        lit(\"You are building a question-answering dataset to evaluate an AI assistant trained on product documentation.\"),\n",
    "        lit(\"Based on the following technical guide, generate 3 realistic user questions.\"),\n",
    "        lit(\"Focus on error codes, troubleshooting, and step-by-step usage.\"),\n",
    "        lit(\"Return only a JSON array of questions.\"),\n",
    "        lit(\"Guide title:\"), col(\"title\"),\n",
    "        lit(\"Product:\"), col(\"product_name\"),\n",
    "        lit(\"Guide:\"), col(\"full_guide\")\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Step 3: Call AI_QUERY directly (in Python, no view)\n",
    "questions_raw = guides_with_prompts.select(\n",
    "    \"id\", \"product_name\", \"title\",\n",
    "    expr('AI_QUERY(\"databricks-claude-3-7-sonnet\", question_prompt)').alias(\"questions_json\")\n",
    ")\n",
    "\n",
    "# Step 4: Parse JSON → array<string>\n",
    "questions_parsed = questions_raw.withColumn(\"questions\", from_json(\"questions_json\", ArrayType(StringType())))\n",
    "\n",
    "# Step 5: Explode questions\n",
    "questions = questions_parsed.select(\"id\", \"product_name\", \"title\", explode(\"questions\").alias(\"question\"))\n",
    "# Step 6: Join back with full_guide\n",
    "questions_with_guides = questions.join(guides_df.select(\"id\", \"full_guide\"), on=\"id\", how=\"inner\")\n",
    "\n",
    "# Step 7: Build prompt to get expected facts\n",
    "questions_with_facts_prompt = questions_with_guides.withColumn(\n",
    "    \"fact_prompt\",\n",
    "    concat_ws(\n",
    "        \" \",\n",
    "        lit(\"You are evaluating an AI system. Based on the following product guide:\"),\n",
    "        col(\"full_guide\"),\n",
    "        lit(\"Return a JSON array of distinct factual statements (expected_facts) that would appear in a correct, helpful answer to the question.\"),\n",
    "        lit(\"Each fact must be concise, complete, and non-redundant.\"),\n",
    "        lit(\"Avoid repeating the same point in different words.\"),\n",
    "        lit(\"Use full, natural language sentences.\"),\n",
    "        lit(\"Return only the JSON array.\"),\n",
    "        lit(\"Question:\"), col(\"question\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 8: Call AI_QUERY again for expected_facts\n",
    "facts_raw = questions_with_facts_prompt.select(\n",
    "    \"question\",\n",
    "    expr('AI_QUERY(\"databricks-claude-3-7-sonnet\", fact_prompt)').alias(\"expected_facts_json\")\n",
    ")\n",
    "\n",
    "\n",
    "# Step 9: Parse JSON array → array<string>\n",
    "facts_df = facts_raw.withColumn(\"expected_facts\", from_json(\"expected_facts_json\", ArrayType(StringType())))\n",
    "\n",
    "# Step 10: Build final eval format\n",
    "eval_guides_df = facts_df.withColumn(\"inputs\", struct(\"question\")) \\\n",
    "                         .withColumn(\"predictions\", lit(\"\")) \\\n",
    "                         .withColumn(\"expectations\", struct(\"expected_facts\")) \\\n",
    "                         .select(\"inputs\", \"predictions\", \"expectations\")\n",
    "\n",
    "eval_guides_df.write.format('json').mode(\"append\").save(f\"/Volumes/{catalog}/{dbName}/{volume_name}/eval_dataset\")\n",
    "# Preview the result\n",
    "display(spark.read.json(f\"/Volumes/{catalog}/{dbName}/{volume_name}/eval_dataset\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_c75093c8-0895-475e-8c1b-6acacfe3368b",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04-eval-dataset-generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
